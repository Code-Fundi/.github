<p align="center">
 <img width="150px" src="https://raw.githubusercontent.com/Code-Fundi/.github/main/media/gradient-bg-logo.png" align="center" alt="Code Fundi" />
 <h2 align="center"><b>Code Fundi</b></h2>
 <p align="center">An AI assistant that helps you write better code faster.</p>
 </br>
</p>

<p align="center">
  <a href="https://discord.gg/6RJTWCuWZj">
    <img src="https://img.shields.io/badge/Discord-7289DA?logo=discord&logoColor=white" />
  </a>
  <a href="https://twitter.com/code_fundi">
    <img src="https://img.shields.io/badge/Twitter-00acee?logo=twitter&logoColor=white" />
  </a>
  <a href="https://www.tiktok.com/@codefundi">
    <img src="https://img.shields.io/badge/TikTok-000000?logo=tiktok&logoColor=white" />
  </a>
<br />
</p>


#

Code Fundi is an AI assistant extension for Visual Studio Code that helps you write better code faster by providing personalized suggestions and insights.
<br/>
<br/>
From interactive code generation and explanation to debugging and test generation, Code Fundi uses [LLMs](https://en.wikipedia.org/wiki/Large_language_model) to help come up with solutions to coding challenges and streamline the development process.
<br/>
<br/>

<p align="center">
  <img src="https://raw.githubusercontent.com/Code-Fundi/.github/main/media/vscode.png" alt="App screenshot">
  <br />
  <br />
</p>

# Installation Guide

Coming Soon ðŸš€
<br />
<br />

# Documentation

- [Code Fundi Docs](https://code-fundi-docs.vercel.app/)
<br />
<br />

# Architecture

This project uses our very own `STNGS` stack.

- Supabase
- Typescript
- NextJS
- GraphQL
- Svelte 
<br />
<br />

# Why LLM?

Since LLMs (Large Language Models) perform well at a wide variety of tasks, it allows them to excel at a different things simultaneously.

One of those tasks is predicting the next word in a sentence which allows them to capture the syntax and semantics of human language. This offers users who interact with these models a seamless experience as they are able to use natural language and ask open ended questions.

Finally, LLMs have shown impressive general knowledge about the world and are able to remember a lot of facts through training. This lets users gain real world information whenever they interact with our models.

This also provides us with plenty of room for growth as we continue training our models to create a better assistant that helps developers everywhere improve their workflows.